# [Anomaly Detection using Variational autoencoder](https://github.com/amousavi9/Anomaly-Detection-using-VAE)
VAEs mostly shine as generative models, but the advantages of generating a smooth and continuous latent space can also be of value for anomaly detection tasks. The idea behind Anomaly Detection is to detect samples that are far from what is usually seen, in some sense or other.         
In this work, we use the Chest X-Ray dataset to construct an anomaly detection problem. For anomaly detection, it is common to train the autoencoders on “normal” data only. We’ll be doing the same and training our VAE on healthy data (class 0). However, checking the performance of the anomaly detection will be completed using all the data. In other words, we’ll be training our VAE on the “slim” data sets, but testing on the “full” data sets. This technique is called semi-supervised because the model has only seen normal data during training. In real-world scenarios, we don’t necessarily have labeled anomalies; under such circumstances the semi-supervised method is especially useful.


# Result
The image below shows a scatter plot of the latent space generated by the encoder (after dim reduction to 2 dims). We can clearly see one large cluster of points that seem quite on the normal side, and next to that we see another cluster of points that are anomalies.
<p align="left" width="100%">
    <img width="50%" src="https://github.com/amousavi9/Anomaly-Detection-using-VAE/blob/main/figs/latent_space.jpg">
</p>

# Evaluation
The figure below shows the total loss (reconstruction and KL divergence) for the training set.
<p align="left" width="100%">
    <img width="50%" src="https://github.com/amousavi9/Anomaly-Detection-using-VAE/blob/main/figs/loss.jpg">
</p>
